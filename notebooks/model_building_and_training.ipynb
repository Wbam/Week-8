{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Credit Card Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 636.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9993\n",
      "Precision: 0.8673\n",
      "Recall: 0.6250\n",
      "F1 Score: 0.7265\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Logistic Regression.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 350.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "Accuracy: 0.9992\n",
      "Precision: 0.7333\n",
      "Recall: 0.8088\n",
      "F1 Score: 0.7692\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Decision Tree.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 466.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.9996\n",
      "Precision: 0.9244\n",
      "Recall: 0.8088\n",
      "F1 Score: 0.8627\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Random Forest.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 466.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boosting\n",
      "Accuracy: 0.9986\n",
      "Precision: 0.8947\n",
      "Recall: 0.1250\n",
      "F1 Score: 0.2194\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Gradient Boosting.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 212.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Multi-Layer Perceptron\n",
      "Accuracy: 0.9995\n",
      "Precision: 0.8974\n",
      "Recall: 0.7721\n",
      "F1 Score: 0.8300\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Multi-Layer Perceptron.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n",
      "Training on Fraud Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 538.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9070\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Logistic Regression.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 291.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "Accuracy: 0.8884\n",
      "Precision: 0.4132\n",
      "Recall: 0.4759\n",
      "F1 Score: 0.4424\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Decision Tree.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:04<00:00,  1.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.9342\n",
      "Precision: 0.8815\n",
      "Recall: 0.3386\n",
      "F1 Score: 0.4893\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Random Forest.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 636.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boosting\n",
      "Accuracy: 0.9070\n",
      "Precision: 0.6000\n",
      "Recall: 0.0014\n",
      "F1 Score: 0.0028\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Gradient Boosting.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 500.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Multi-Layer Perceptron\n",
      "Accuracy: 0.9070\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Saved model to: C:/Users/bam/Desktop/Week-8/notebooks/trained_model_Multi-Layer Perceptron.joblib\n",
      "Saved metrics to: C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\n",
      "Saved predictions to: C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "\n",
    "# Load the datasets\n",
    "fraud_data = pd.read_csv('C:/Users/bam/Documents/Data/Fraud_Data.csv')\n",
    "creditcard_data = pd.read_csv('C:/Users/bam/Documents/Data/creditcard.csv')\n",
    "\n",
    "# Specify target and features for each dataset\n",
    "X_fraud = fraud_data.drop(columns=['class'])\n",
    "y_fraud = fraud_data['class']\n",
    "X_creditcard = creditcard_data.drop(columns=['Class'])\n",
    "y_creditcard = creditcard_data['Class']\n",
    "\n",
    "# Convert date columns to datetime and extract year, month, day, hour \n",
    "for df in [X_fraud, X_creditcard]:\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[col]) and 'date' in col.lower():\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            df['year'] = df[col].dt.year\n",
    "            df['month'] = df[col].dt.month\n",
    "            df['day'] = df[col].dt.day\n",
    "            df['hour'] = df[col].dt.hour\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Train-Test Split\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(X_fraud, y_fraud, test_size=0.3, random_state=42)\n",
    "X_cc_train, X_cc_test, y_cc_train, y_cc_test = train_test_split(X_creditcard, y_creditcard, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize/Scale features\n",
    "scaler = StandardScaler()\n",
    "X_fraud_train = scaler.fit_transform(X_fraud_train.select_dtypes(include='number'))\n",
    "X_fraud_test = scaler.transform(X_fraud_test.select_dtypes(include='number'))\n",
    "X_cc_train = scaler.fit_transform(X_cc_train.select_dtypes(include='number'))\n",
    "X_cc_test = scaler.transform(X_cc_test.select_dtypes(include='number'))\n",
    "\n",
    "# Initialize Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Multi-Layer Perceptron\": MLPClassifier(max_iter=500)\n",
    "}\n",
    "\n",
    "# MLflow Tracking\n",
    "mlflow.set_experiment(\"Fraud Detection Project\")\n",
    "\n",
    "# Function to save evaluation metrics to a CSV file\n",
    "def save_metrics_to_csv(model_name, metrics, filename):\n",
    "    df = pd.DataFrame(metrics, index=[0])\n",
    "    df.to_csv(filename, mode='a', header=not pd.io.common.file_exists(filename), index=False)\n",
    "\n",
    "# Function to save predictions to a CSV file\n",
    "def save_predictions_to_csv(model_name, y_pred, filename):\n",
    "    df = pd.DataFrame(y_pred, columns=['Predictions'])\n",
    "    df['Model'] = model_name\n",
    "    df.to_csv(filename, mode='a', header=not pd.io.common.file_exists(filename), index=False)\n",
    "\n",
    "# Training and Evaluation Function\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    with mlflow.start_run():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Prepare metrics for saving\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1\n",
    "        }\n",
    "\n",
    "        # Log model and metrics to MLflow\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"model_type\", type(model).__name__)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # Prepare input example for model logging\n",
    "        input_example = X_test[0:1]  # Use the first row as an example\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, model_name, input_example=input_example)\n",
    "\n",
    "        # Save the trained model to a joblib file\n",
    "        joblib_file_path = f\"C:/Users/bam/Desktop/Week-8/notebooks/trained_model_{model_name}.joblib\"\n",
    "        joblib.dump(model, joblib_file_path)\n",
    "\n",
    "        # Save metrics to a CSV file\n",
    "        metrics_file_path = \"C:/Users/bam/Desktop/Week-8/notebooks/model_metrics.csv\"\n",
    "        save_metrics_to_csv(model_name, metrics, metrics_file_path)\n",
    "\n",
    "        # Save predictions to a CSV file\n",
    "        predictions_file_path = \"C:/Users/bam/Desktop/Week-8/notebooks/predictions.csv\"\n",
    "        save_predictions_to_csv(model_name, y_pred, predictions_file_path)\n",
    "\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Saved model to: {joblib_file_path}\")\n",
    "        print(f\"Saved metrics to: {metrics_file_path}\")\n",
    "        print(f\"Saved predictions to: {predictions_file_path}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Train and evaluate models on Credit Card Data\n",
    "print(\"Training on Credit Card Data...\")\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model, X_cc_train, X_cc_test, y_cc_train, y_cc_test, model_name)\n",
    "\n",
    "# Train and evaluate models on Fraud Data\n",
    "print(\"Training on Fraud Data...\")\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model, X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
